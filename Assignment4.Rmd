---
title: "DSC5103 Assignment 4"
subtitle: 'Regularization Methods in Classification'
author: "Tong Wang"
date: "Oct 2016"
output:
  html_document:
    highlight: tango
    theme: yeti
---
<!--
comments must be put in an HTML comment form
-->

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 100)  # set output width, turn off scientific notation for big numbers
```

## NOTE:
This assignment is **due at 23:59 of Oct 13, Thursday**. You can work on this file directly and fill in your answers/code below. Please submit the output HTML file (name your file like G1Group02.html if you are from Group 02 of Section G1) onto IVLE/Files/Student Submission/Assignment4 folder.

Also, put the Section/Group and member info below.
```{r}
# Section G?
# Group ??
# Members: YOUR NAMES HERE
```



### Introduction
In this assignment, we will apply regularization methods (Ridge Regression, LASSO, and Elastic Net) to a classification problem, and compare them with traditional Logistic Regression.

Before we start, it is necessary to read through the documentation of the functions **glmnet()** (specifically, the *family* option), **cv.glmnet()** (the *family* and *type.measure* options), and **predict.glmnet()** (the *type* option) in the **glmnet** package, and find out how to run generalized linear models with regularization.

### Data Preparation
First, let us get the data. We will use the **Heart** data from the textbook, available at http://www-bcf.usc.edu/~gareth/ISL/Heart.csv.
```{r}
heart <- read.csv(file="http://www-bcf.usc.edu/~gareth/ISL/Heart.csv", row.names=1)
summary(heart)
str(heart)
```
The task is to use the features to predict **AHD**, binary outcome related to some heart disease. 

Some cleaning is necessary because there are NA's and also several categorical variables stored as numerical.
```{r}
# clean the NA's
heart <- na.omit(heart)
# convert to factors
heart$Sex <- as.factor(heart$Sex)
heart$Fbs <- as.factor(heart$Fbs)
heart$RestECG <- as.factor(heart$RestECG)
heart$ExAng <- as.factor(heart$ExAng)
heart$Slope <- as.factor(heart$Slope)
heart$Ca <- as.factor(heart$Ca)
summary(heart)
```

Next, we will prepare the training and test dataset for later model comparison.
```{r}
# split training and test data 50/50
N <- nrow(heart)
set.seed(456)
train.index <- sample(1:N, round(N/2))
test.index <- - train.index
```
Because function **glmnet()** only takes data in matrix form, we need a copy of the training and test data in matrix form.
```{r}
# construct x and y matrix for glmnet()
x <- model.matrix(AHD ~ ., heart[train.index, ])[, -1]
y <- heart[train.index, "AHD"]
x.test <- model.matrix(AHD ~ ., heart[-train.index, ])[, -1]
y.test <- heart[-train.index, "AHD"]
```


### Questions and Answers
#### 1. [Logistic Regression as a benchmark] Find the optimal Logistic Regression model with **stepAIC()** using the training data, and use the model to predict using the test data.  (1 Mark)

Answer: 

```{r}
# put your R code here inside the blocks
library("MASS")
y1 <- as.numeric(y)
y1 <- y1 - 1
data1 <- data.frame(cbind(y1, x))
colnames(data1)[1]  <- "AHD"
str(data1)
summary(data1)
glm1 <- glm(AHD ~ ., data=data1, family=binomial())
summary(glm1)
step.opt <- stepAIC(glm1, direction="backward")
step.opt
summary(step.opt)


x.test1 <- data.frame(x.test)
str(x.test1)
#x.test1 <- x.test1[, c("Age", "Sex1", "ChestPainnonanginal", "RestBP", 
                       #"Chol", "MaxHR", "Slope2", "Slope3" , "Ca1", "Ca2", "Ca3", "Thalreversable")]
pred.glm <- predict(step.opt, newdata=x.test1, type="response")

```



#### 2. [Ridge Regression] Fit a Ridge Regression model on the training data, use cross-validtion to find the optimal $\lambda$, and use the optimal model to predict on the test data.  (1 Mark)

Answer: 

```{r}
# put your R code here inside the blocks

library("glmnet")
?glmnet
ridge.mod <- glmnet(x, y, alpha=0, family="binomial")
ridge.cv <- cv.glmnet(x, y, alpha=0, family="binomial")

ridge.lam2 <- ridge.cv$lambda.1se
log(ridge.lam2)
min(ridge.cv$cvm) + ridge.cv$cvsd[which.min(ridge.cv$cvm)]
points(log(ridge.lam2), min(ridge.cv$cvm) + ridge.cv$cvsd[which.min(ridge.cv$cvm)])
pred.rid <- predict(ridge.mod, s=ridge.lam2, newx=x.test, exact=TRUE, type="response")
```


#### 3. [LASSO] Fit a LASSO model on the training data, use cross-validtion to find the optimal $\lambda$, and use the optimal model to predict on the test data.  (1 Mark)

Answer: 

```{r}
# put your R code here inside the blocks
lasso.mod <- glmnet(x, y, alpha=1,family="binomial")
lasso.cv <- cv.glmnet(x, y, alpha=1,family="binomial")

lasso.lam2 <- lasso.cv$lambda.1se
log(lasso.lam2)
min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)]
points(log(lasso.lam2), min(lasso.cv$cvm) + lasso.cv$cvsd[which.min(lasso.cv$cvm)], cex=3)
pred.lasso <-  predict(lasso.mod, s=lasso.lam2, newx=x.test, exact=TRUE,type="response")
```


#### 4. [Elastic Net] Fit an Elastic Net model on the training data, use cross-validtion to find the optimal $\alpha$ and $\lambda$, and use the optimal model to predict on the test data.  (1 Mark)

Answer: 

```{r}
# put your R code here inside the blocks
K <- 10
n <- nrow(x)
fold <- rep(0, n)
shuffled.index <- sample(n, n, replace=FALSE)
fold[shuffled.index] <- rep(1:K, length.out=n)
table(fold)

alphas <- seq(0, 1, 0.1)
en2.cv.error <- data.frame(alpha=alphas)
for (i in 1:length(alphas)){
    en2.cv <- cv.glmnet(x, y, alpha=alphas[i], foldid=fold, family="binomial")
    en2.cv.error[i, "lambda.min"] <- en2.cv$lambda.min
    en2.cv.error[i, "error.min"] <- min(en2.cv$cvm)
    en2.cv.error[i, "lambda.1se"] <- en2.cv$lambda.1se
    en2.cv.error[i, "error.1se"] <- min(en2.cv$cvm) + en2.cv$cvsd[which.min(en2.cv$cvm)]
}
en2.cv.error
en2.lam2 <- en2.cv.error[which.min(en2.cv.error$error.1se), "lambda.1se"]
en2.alpha2 <- en2.cv.error[which.min(en2.cv.error$error.1se), "alpha"]
en2.lam2 
en2.alpha2

en2.mod <- glmnet(x, y, alpha=en2.alpha2, family="binomial")
pred.elas <-  predict(en2.mod, s=en2.lam2, newx=x.test, exact=TRUE,type="response")

```



#### 5. Compare the above-studied model predictions in terms of misclassification rate, ROC, and AUC.  (1 Mark)

Answer: 

```{r}
# put your R code here inside the blocks
library("ROCR")
glm.pred <- prediction(pred.glm, y.test)
rid.pred <- prediction(pred.rid, y.test)
lasso.pred <- prediction(pred.lasso, y.test)
elas.pred <- prediction(pred.elas,y.test)


#error rate
glm.err <- performance(glm.pred, measure="err")
rid.err <- performance(rid.pred, measure="err")
lasso.err <- performance(lasso.pred, measure="err")
elas.err <- performance(elas.pred, measure="err")

plot(glm.err, col="yellow")
plot(rid.err, col="black", add=TRUE)
plot(lasso.err, col="blue", add=TRUE)
plot(elas.err, col="red", add=TRUE)
legend(x=0.1, y=0.3, legend=c("glm.err","rid.err", "lasso.err", "elas.err"), lty=c(1, 1, 1, 1), lwd=c(2, 2, 2, 2), col=c("yellow","black", "blue", "red"))

#Roc
glm.ROC <- performance(glm.pred, measure="tpr", x.measure="fpr")
rid.ROC <- performance(rid.pred, measure="tpr", x.measure="fpr")
lasso.ROC <- performance(lasso.pred, measure="tpr", x.measure="fpr")
elas.ROC <- performance(elas.pred, measure="tpr", x.measure="fpr")

plot(glm.ROC, col="yellow")
plot(rid.ROC, col="black", add=TRUE)
plot(lasso.ROC, col="blue", add=TRUE)
plot(elas.ROC, col="red", add=TRUE)
abline(a=0, b=1, lty=2) # diagonal line
legend(x=0.9, y=0.5, legend=c("glm.err","rid.err", "lasso.err", "elas.err"), lty=c(1, 1, 1, 1), lwd=c(2, 2, 2, 2), col=c("yellow","black", "blue", "red"))

#AUC
glm.auc <- performance(glm.pred, "auc")
as.numeric(glm.auc@y.values)

rid.auc <- performance(rid.pred, "auc")
as.numeric(rid.auc@y.values)

lasso.auc <- performance(lasso.pred, "auc")
as.numeric(lasso.auc@y.values)

elas.auc <- performance(elas.pred, "auc")
as.numeric(elas.auc@y.values)


```
