---
title: "DSC5103 Assignment 4"
subtitle: 'Regularization Methods in Classification'
author: "Tong Wang"
date: "Oct 2016"
output:
  html_document:
    highlight: tango
    theme: yeti
---
<!--
comments must be put in an HTML comment form
-->

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 100)  # set output width, turn off scientific notation for big numbers
```

## NOTE:
This assignment is **due at 23:59 of Oct 13, Thursday**. You can work on this file directly and fill in your answers/code below. Please submit the output HTML file (name your file like G1Group02.html if you are from Group 02 of Section G1) onto IVLE/Files/Student Submission/Assignment4 folder.

Also, put the Section/Group and member info below.
```{r}
# Section G?
# Group ??
# Members: YOUR NAMES HERE
```



### Introduction
In this assignment, we will apply regularization methods (Ridge Regression, LASSO, and Elastic Net) to a classification problem, and compare them with traditional Logistic Regression.

Before we start, it is necessary to read through the documentation of the functions **glmnet()** (specifically, the *family* option), **cv.glmnet()** (the *family* and *type.measure* options), and **predict.glmnet()** (the *type* option) in the **glmnet** package, and find out how to run generalized linear models with regularization.

### Data Preparation
First, let us get the data. We will use the **Heart** data from the textbook, available at http://www-bcf.usc.edu/~gareth/ISL/Heart.csv.
```{r}
heart <- read.csv(file="http://www-bcf.usc.edu/~gareth/ISL/Heart.csv", row.names=1)
summary(heart)
```
The task is to use the features to predict **AHD**, binary outcome related to some heart disease. 

Some cleaning is necessary because there are NA's and also several categorical variables stored as numerical.
```{r}
# clean the NA's
heart <- na.omit(heart)
# convert to factors
heart$Sex <- as.factor(heart$Sex)
heart$Fbs <- as.factor(heart$Fbs)
heart$RestECG <- as.factor(heart$RestECG)
heart$ExAng <- as.factor(heart$ExAng)
heart$Slope <- as.factor(heart$Slope)
heart$Ca <- as.factor(heart$Ca)
summary(heart)
```

Next, we will prepare the training and test dataset for later model comparison.
```{r}
# split training and test data 50/50
N <- nrow(heart)
set.seed(456)
train.index <- sample(1:N, round(N/2))
test.index <- - train.index
```
Because function **glmnet()** only takes data in matrix form, we need a copy of the training and test data in matrix form.
```{r}
# construct x and y matrix for glmnet()
x <- model.matrix(AHD ~ ., heart[train.index, ])[, -1]
y <- heart[train.index, "AHD"]
x.test <- model.matrix(AHD ~ ., heart[-train.index, ])[, -1]
y.test <- heart[-train.index, "AHD"]
```


### Questions and Answers
#### 1. [Logistic Regression as a benchmark] Find the optimal Logistic Regression model with **stepAIC()** using the training data, and use the model to predict using the test data.  (1 Mark)

Answer: 

```{r}
train.data <- heart[train.index, ]
test.data <- heart[-train.index, ]
model.all <- glm(formula = AHD ~ ., family = binomial, data = train.data)

# using the stepAIC() to find the optimal glm model
library(MASS)
model.step <- stepAIC(model.all, direction = "both")
model.glm <- model.step
summary(model.glm)

# use the model to predict
glm.prob <- predict(model.glm, newdata = test.data, type = "response")
glm.pred <- glm.prob >= 0.5
```



#### 2. [Ridge Regression] Fit a Ridge Regression model on the training data, use cross-validtion to find the optimal $\lambda$, and use the optimal model to predict on the test data.  (1 Mark)

Answer: 

```{r}
library("glmnet")
# Fit a Ridge Regression model on the training data
ridge.mod <- glmnet(x, y, family = "binomial", alpha=0) 
str(ridge.mod)

# use cross-validtion to find the optimal $\lambda$ 
ridge.cv <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha=0)
plot(ridge.cv)
ridge.lam <- ridge.cv$lambda.min
# the optimal lamda
ridge.lam
# plot the optimal point
log(ridge.lam)
min(ridge.cv$cvm)
points(log(ridge.lam), min(ridge.cv$cvm), cex=3)
# plot the optimal lamda
plot(ridge.mod, xvar="lambda", label = TRUE)
abline(v=log(ridge.lam), lty=2)

# prediciton using optimal model
ridge.prob <- predict(ridge.mod, s=ridge.lam, newx=x.test, type = "response", exact=TRUE)
ridge.pred <- predict(ridge.mod, s=ridge.lam, newx=x.test, type = "class", exact=TRUE)
```


#### 3. [LASSO] Fit a LASSO model on the training data, use cross-validtion to find the optimal $\lambda$, and use the optimal model to predict on the test data.  (1 Mark)

Answer: 

```{r}
# Fit a LASSO Regression model on the training data
lasso.mod <- glmnet(x, y, family = "binomial", alpha=1) 
str(lasso.mod)

# use cross-validtion to find the optimal $\lambda$ 
lasso.cv <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha=1)
plot(lasso.cv)
lasso.lam <- lasso.cv$lambda.min
# the optimal lamda
lasso.lam
# plot the optimal point
log(lasso.lam)
min(lasso.cv$cvm)
points(log(lasso.lam), min(lasso.cv$cvm), cex=3)
# plot the optimal lamda
plot(lasso.mod, xvar="lambda", label = TRUE)
abline(v=log(lasso.lam), lty=2)

# prediciton using optimal model
lasso.prob <- predict(lasso.mod, s=lasso.lam, newx=x.test, type = "response", exact=TRUE)
lasso.pred <- predict(lasso.mod, s=lasso.lam, newx=x.test, type = "class", exact=TRUE)
```


#### 4. [Elastic Net] Fit an Elastic Net model on the training data, use cross-validtion to find the optimal $\alpha$ and $\lambda$, and use the optimal model to predict on the test data.  (1 Mark)

Answer: 

```{r}
# random partition for 10-fold cross-validation
K <- 10
n <- nrow(x)
fold <- rep(0, n)
set.seed(2)
shuffled.index <- sample(n, n, replace=FALSE)
fold[shuffled.index] <- rep(1:K, length.out=n)

# cross-validation to find the best alpha-lambda combination
alphas <- seq(0, 1, 0.1)
en.cv.error <- data.frame(alpha=alphas)
for (i in 1:length(alphas)){
    en.cv <- cv.glmnet(x, y, alpha=alphas[i], family = "binomial", type.measure = "class", foldid=fold)
    en.cv.error[i, "lambda.min"] <- en.cv$lambda.min
    en.cv.error[i, "error.min"] <- min(en.cv$cvm)
}
en.cv.error

# optimal lambda and alpha
en.lam <- en.cv.error[which.min(en.cv.error$error.min), "lambda.min"]
en.alpha <- en.cv.error[which.min(en.cv.error$error.min), "alpha"]

# the optimal model
en.mod <- glmnet(x, y, family = "binomial", alpha=en.alpha)
plot(en.mod, xvar="lambda", label = TRUE)
abline(v=log(en.lam), lty=2)

# prediciton using optimal model
en.prob <- predict(en.mod, s=en.lam, newx=x.test, type = "response", exact=TRUE)
en.pred <- predict(en.mod, s=en.lam, newx=x.test, type = "class", exact=TRUE)
```



#### 5. Compare the above-studied model predictions in terms of misclassification rate, ROC, and AUC.  (1 Mark)

Answer: 

```{r}
library("ROCR")
glm.mat <- table(y.test, glm.pred)
ridge.mat <- table(y.test, ridge.pred)
lasso.mat <- table(y.test, lasso.pred)
en.mat <- table(y.test, en.pred)

# measuring misclassification rate
misclass <- matrix(rep(0,4), nrow = 4, ncol = 1, dimnames = list(c("glm", "ridge", "lasso", "en"), "misclassification rate"))
misclass["glm", ] <- (glm.mat[1,2]+glm.mat[2,1])/length(y.test)
misclass["ridge", ] <- (ridge.mat[1,2]+ridge.mat[2,1])/length(y.test)
misclass["lasso", ] <- (lasso.mat[1,2]+lasso.mat[2,1])/length(y.test)
misclass["en", ] <- (en.mat[1,2]+en.mat[2,1])/length(y.test)
misclass

# construction prediction models
pred.glm <- prediction(glm.prob, y.test)
pred.ridge <- prediction(ridge.prob, y.test)
pred.lasso <- prediction(lasso.prob, y.test)
pred.en <- prediction(en.prob, y.test)

# ROC plots
par(mfrow=c(2,2))
glm.ROC <- performance(pred.glm, measure="tpr", x.measure="fpr")
plot(glm.ROC, main = "ROC plot of Logistic Regression")
abline(a=0, b=1, lty=2)

ridge.ROC <- performance(pred.ridge, measure="tpr", x.measure="fpr")
plot(ridge.ROC, main = "ROC plot of Ridge Regression")
abline(a=0, b=1, lty=2)

lasso.ROC <- performance(pred.lasso, measure="tpr", x.measure="fpr")
plot(lasso.ROC, main = "ROC plot of LASSO Regression")
abline(a=0, b=1, lty=2)

en.ROC <- performance(pred.en, measure="tpr", x.measure="fpr")
plot(en.ROC, main = "ROC plot of Elastic Net Regression")
abline(a=0, b=1, lty=2)

par(mfrow=c(1,1))

# measuring AUC
auc <- matrix(rep(0,4), nrow = 4, ncol = 1, dimnames = list(c("glm", "ridge", "lasso", "en"), "AUC"))

glm.auc <- performance(pred.glm, measure = "auc")
auc["glm", ] <- as.numeric(glm.auc@y.values)

ridge.auc <- performance(pred.ridge, measure = "auc")
auc["ridge", ] <- as.numeric(ridge.auc@y.values)

lasso.auc <- performance(pred.lasso, measure = "auc")
auc["lasso", ] <- as.numeric(lasso.auc@y.values)

en.auc <- performance(pred.en, measure = "auc")
auc["en", ] <- as.numeric(en.auc@y.values)
auc
```
